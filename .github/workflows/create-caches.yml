name: Create Caches

on: workflow_dispatch

jobs:
  build:
    strategy:
      matrix:
        os:
          - ubuntu-latest
          - macos-12
    name: Create Caches on ${{ matrix.os }} conda
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout sources
        uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Setup conda
        uses: s-weigand/setup-conda@v1
        with:
          update-conda: true
          python-version: 3.9
          conda-channels: pytorch, anaconda, conda-forge

      - name: Set platform variables
        id: vars
        run: |
          [[ "$RUNNER_OS" == "macOS" ]] \
            && echo "CONDA_ENV_FILE=environment-mac.yml" >> $GITHUB_OUTPUT
          [[ "$RUNNER_OS" == "Linux" ]] \
            && echo "CONDA_ENV_FILE=environment.yml" >> $GITHUB_OUTPUT
          echo "CONDA_ROOT=$CONDA" >> $GITHUB_OUTPUT

      - name: Use Cached Stable Diffusion v1.4 Model
        id: cache-sd-v1-4
        uses: actions/cache@v3
        env:
          cache-name: cache-sd-v1-4
        with:
          path: models/ldm/stable-diffusion-v1/model.ckpt
          key: ${{ env.cache-name }}
          restore-keys: |
            ${{ env.cache-name }}

      - name: Download Stable Diffusion v1.4 Model
        if: ${{ steps.cache-sd-v1-4.outputs.cache-hit != 'true' }}
        run: |
          [[ -e models/ldm/stable-diffusion-v1 ]] \
            || mkdir -p models/ldm/stable-diffusion-v1
          [[ -e models/ldm/stable-diffusion-v1/model.ckpt ]] \
            || curl -o models/ldm/stable-diffusion-v1/model.ckpt ${{ secrets.SD_V1_4_URL }}

      - name: Use Cached Dependencies
        id: cache-conda-env-invokeai
        uses: actions/cache@v3
        env:
          cache-name: cache-conda-env-invokeai
          conda-root: ${{ steps.vars.outputs.CONDA_ROOT }}
        with:
          path: ${{ env.conda-root }}/envs/invokeai
          key: ${{ env.cache-name }}
          restore-keys: |
            ${{ env.cache-name }}-${{ runner.os }}-${{ hashFiles(steps.vars.outputs.CONDA_ENV_FILE) }}

      - name: Install Dependencies
        if: ${{ steps.cache-conda-env-invokeai.outputs.cache-hit != 'true' }}
        run: |
          conda env update \
            --file ${{ steps.vars.outputs.CONDA_ENV_FILE }} \
            --name invokeai

      - name: Use Cached Huggingface and Torch models
        id: cache-hugginface-torch
        uses: actions/cache@v3
        env:
          cache-name: cache-hugginface-torch
        with:
          path: ~/.cache
          key: ${{ env.cache-name }}
          restore-keys: |
            ${{ env.cache-name }}-${{ hashFiles('scripts/preload_models.py') }}

      - name: Download Huggingface and Torch models
        if: ${{ steps.cache-hugginface-torch.outputs.cache-hit != 'true' }}
        run: |
          $CONDA/envs/invokeai/bin/python scripts/preload_models.py
